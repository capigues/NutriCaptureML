{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3965ba81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imageio import imread\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b6a0339",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bangbang-chicken', 'bean-sauce', 'boiled-fish-with-pickled-chinese-cabbage', 'boiled-mutton', 'boiled-pork-with-mashed-garlic', 'braised-bear-paw', 'chicken-with-sesasme-paste', 'chongqing-spicy-deep-fried-chicken', 'crisp-duck-roasted-with-camphor-and-tea', 'dan-dan-mian', 'dongpo-cuttlefish', 'dry-fried-carp', 'dry-fried-string-beans', 'duck-blood-in-chili-sauce', 'duck-hotpot', 'fish-flavored-pork-shreds', 'fu-qi-fei-pan', 'husbands-and-wifes-pork-lungs', 'kung-pao-chicken', 'latern-shadow-beef', 'minced-chicken-with-hollyhock', 'noodles-with-chili-sauce', \"pockmarked-lady's-bean-curd-(mapo-tofu)\", 'rice-dumplings-with-sesame-paste', 'sea-cucumber', 'sesame-oil-chicken', 'sliced-beef-and-ox-organs-in-chili-sauce', 'sliced-pork-in-hot-chili-oil', 'spicy-diced-chicken-with-peanuts', 'steamed-beef', 'steamed-pork-with-spicy-cabbage', 'twice-cooked-pork-with-chili-sauce', 'velvet-sharks-fin', 'water-boiled-beef', 'water-poached-fish', 'zhong-shui-jiao'] 36\n"
     ]
    }
   ],
   "source": [
    "# Load Classnames\n",
    "path='/Users/cap/Dropbox/Cuisines'\n",
    "img_path='/Users/cap/Dropbox/Cuisines/images'\n",
    "classes = []\n",
    "num_foods = 0\n",
    "img_count = 102\n",
    "\n",
    "for file in os.listdir(img_path):\n",
    "    if (file.startswith('.')): continue #ignore hidden files\n",
    "    classes.append(file)\n",
    "\n",
    "num_foods = len(classes)\n",
    "    \n",
    "'''\n",
    "# More legible food names\n",
    "for i in range (0, num_foods-1):\n",
    "    if (dir_list[i].startswith('.')): continue #ignore hidden files\n",
    "    class_name = ''\n",
    "    for char in dir_list[i]:\n",
    "        if (char == '-'):\n",
    "            class_name += \" \"\n",
    "        else:\n",
    "            class_name += char\n",
    "    classes.append(class_name.title())\n",
    "'''\n",
    "\n",
    "food_names = sorted(classes)\n",
    "print(food_names, num_foods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c030f872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: bangbang-chicken\n",
      "['bang-bang-chicken-8.jpg', '05542cfd530dfe596a122a65f26837b9.jpg', 'Bang-Bang-Chicken-819x1024.jpg', '75c53e2b6db04fe233c96c138c374a05.jpg', 'szechuan-chicken-5.jpg', '74bd4c3204c9b72f1f000c641574ff0c.jpg', 'download.jpg', 'd6fbd5ed99fa1d06a4ff81201dc98547.jpg', '68afb09c067356df819416a2a454c3e6.jpg', 'Sichuan-Bang-Bang-Chicken-7.jpg', '4728c1f876fdbcb33b08b571151ccd64.jpg', 'e0803deac5359f795620c01b3bfa86bf.jpg', 'images-1.jpg', '6ff5bb7d1f1e2b5c0cbaeae49b12b497.jpg', 'images-2.jpg', 'a5206908799e6b861c90620431180a71.jpg', 'd316dcfe3f35c104317dc78b048ba1fc.jpg', '8f044acd425550f197b8b96259e1253f.jpg', 'c7b20a024c6009350c357423eb81b660.jpg', '452cc92801c25531976a93548551a8ad.jpg', '4df63155c6aceda5a6f49be99a7922de.jpg', 'download-3.jpg', 'download-2.jpg', '1910_Chinese-Bang-Bang-Chicken_550.jpg']\n",
      "test: bangbang-chicken\n",
      "['c7f2d0b1d1c330229d217b0b97c777df.jpg', 'download-1.jpg', 'OIP.jpg', 'download-4.jpg', 'dca167ef02cfae3b5bc2f548e5192f67.jpg', 'images.jpg']\n",
      "\n",
      "\n",
      "train: bean-sauce\n",
      "['download.jpg', 'images-4.jpg', 'images-1.jpg', 'images-2.jpg', 'images-3.jpg', 'download-3.jpg', 'download-2.jpg', 'download-1.jpg']\n",
      "test: bean-sauce\n",
      "['download-5.jpg', 'download-4.jpg', 'images.jpg']\n",
      "\n",
      "\n",
      "train: boiled-fish-with-pickled-chinese-cabbage\n",
      "['download-9.jpg', 'download-8.jpg', 'download.jpg', 'images-1.jpg', 'download-3.jpg', 'download-2.jpg', 'download-11.jpg', 'download-1.jpg', 'download-10.jpg', 'download-5.jpg', 'download-4.jpg']\n",
      "test: boiled-fish-with-pickled-chinese-cabbage\n",
      "['images.jpg', 'download-6.jpg', 'download-7.jpg']\n",
      "\n",
      "\n",
      "train: boiled-mutton\n",
      "['download.jpg', 'images-1.jpg', 'images-2.jpg', 'download-3.jpg', 'download-2.jpg', 'download-1.jpg', 'download-5.jpg', 'download-4.jpg']\n",
      "test: boiled-mutton\n",
      "['images.jpg', 'download-6.jpg']\n",
      "\n",
      "\n",
      "train: boiled-pork-with-mashed-garlic\n",
      "['download-9.jpg', 'download-8.jpg', 'download.jpg', 'images-1.jpg', 'download-3.jpg', 'download-2.jpg', 'download-1.jpg', 'download-10.jpg', 'download-5.jpg', 'download-4.jpg']\n",
      "test: boiled-pork-with-mashed-garlic\n",
      "['images.jpg', 'download-6.jpg', 'download-7.jpg']\n",
      "\n",
      "\n",
      "train: braised-bear-paw\n",
      "[]\n",
      "test: braised-bear-paw\n",
      "[]\n",
      "\n",
      "\n",
      "train: chicken-with-sesasme-paste\n",
      "[]\n",
      "test: chicken-with-sesasme-paste\n",
      "[]\n",
      "\n",
      "\n",
      "train: chongqing-spicy-deep-fried-chicken\n",
      "[]\n",
      "test: chongqing-spicy-deep-fried-chicken\n",
      "[]\n",
      "\n",
      "\n",
      "train: crisp-duck-roasted-with-camphor-and-tea\n",
      "[]\n",
      "test: crisp-duck-roasted-with-camphor-and-tea\n",
      "[]\n",
      "\n",
      "\n",
      "train: dan-dan-mian\n",
      "[]\n",
      "test: dan-dan-mian\n",
      "[]\n",
      "\n",
      "\n",
      "train: dongpo-cuttlefish\n",
      "[]\n",
      "test: dongpo-cuttlefish\n",
      "[]\n",
      "\n",
      "\n",
      "train: dry-fried-carp\n",
      "[]\n",
      "test: dry-fried-carp\n",
      "[]\n",
      "\n",
      "\n",
      "train: dry-fried-string-beans\n",
      "[]\n",
      "test: dry-fried-string-beans\n",
      "[]\n",
      "\n",
      "\n",
      "train: duck-blood-in-chili-sauce\n",
      "[]\n",
      "test: duck-blood-in-chili-sauce\n",
      "[]\n",
      "\n",
      "\n",
      "train: duck-hotpot\n",
      "[]\n",
      "test: duck-hotpot\n",
      "[]\n",
      "\n",
      "\n",
      "train: fish-flavored-pork-shreds\n",
      "[]\n",
      "test: fish-flavored-pork-shreds\n",
      "[]\n",
      "\n",
      "\n",
      "train: fu-qi-fei-pan\n",
      "[]\n",
      "test: fu-qi-fei-pan\n",
      "[]\n",
      "\n",
      "\n",
      "train: husbands-and-wifes-pork-lungs\n",
      "[]\n",
      "test: husbands-and-wifes-pork-lungs\n",
      "[]\n",
      "\n",
      "\n",
      "train: kung-pao-chicken\n",
      "[]\n",
      "test: kung-pao-chicken\n",
      "[]\n",
      "\n",
      "\n",
      "train: latern-shadow-beef\n",
      "[]\n",
      "test: latern-shadow-beef\n",
      "[]\n",
      "\n",
      "\n",
      "train: minced-chicken-with-hollyhock\n",
      "[]\n",
      "test: minced-chicken-with-hollyhock\n",
      "[]\n",
      "\n",
      "\n",
      "train: noodles-with-chili-sauce\n",
      "[]\n",
      "test: noodles-with-chili-sauce\n",
      "[]\n",
      "\n",
      "\n",
      "train: pockmarked-lady's-bean-curd-(mapo-tofu)\n",
      "[]\n",
      "test: pockmarked-lady's-bean-curd-(mapo-tofu)\n",
      "[]\n",
      "\n",
      "\n",
      "train: rice-dumplings-with-sesame-paste\n",
      "[]\n",
      "test: rice-dumplings-with-sesame-paste\n",
      "[]\n",
      "\n",
      "\n",
      "train: sea-cucumber\n",
      "[]\n",
      "test: sea-cucumber\n",
      "[]\n",
      "\n",
      "\n",
      "train: sesame-oil-chicken\n",
      "[]\n",
      "test: sesame-oil-chicken\n",
      "[]\n",
      "\n",
      "\n",
      "train: sliced-beef-and-ox-organs-in-chili-sauce\n",
      "[]\n",
      "test: sliced-beef-and-ox-organs-in-chili-sauce\n",
      "[]\n",
      "\n",
      "\n",
      "train: sliced-pork-in-hot-chili-oil\n",
      "[]\n",
      "test: sliced-pork-in-hot-chili-oil\n",
      "[]\n",
      "\n",
      "\n",
      "train: spicy-diced-chicken-with-peanuts\n",
      "[]\n",
      "test: spicy-diced-chicken-with-peanuts\n",
      "[]\n",
      "\n",
      "\n",
      "train: steamed-beef\n",
      "[]\n",
      "test: steamed-beef\n",
      "[]\n",
      "\n",
      "\n",
      "train: steamed-pork-with-spicy-cabbage\n",
      "[]\n",
      "test: steamed-pork-with-spicy-cabbage\n",
      "[]\n",
      "\n",
      "\n",
      "train: twice-cooked-pork-with-chili-sauce\n",
      "[]\n",
      "test: twice-cooked-pork-with-chili-sauce\n",
      "[]\n",
      "\n",
      "\n",
      "train: velvet-sharks-fin\n",
      "[]\n",
      "test: velvet-sharks-fin\n",
      "[]\n",
      "\n",
      "\n",
      "train: water-boiled-beef\n",
      "['download.jpg', 'download-2 3.45.05 PM.jpg', 'download 3.45.05 PM.jpg', 'download-3 3.45.05 PM.jpg', 'images 3.45.05 PM.jpg', 'download-4 3.45.05 PM.jpg', 'download-3.jpg', 'download-2.jpg', 'download-6 3.45.05 PM.jpg']\n",
      "test: water-boiled-beef\n",
      "['download-1 3.45.05 PM.jpg', 'download-1.jpg', 'download-8 3.45.05 PM.jpg']\n",
      "\n",
      "\n",
      "train: water-poached-fish\n",
      "[]\n",
      "test: water-poached-fish\n",
      "[]\n",
      "\n",
      "\n",
      "train: zhong-shui-jiao\n",
      "['download.jpg', 'images-4.jpg', 'images-5.jpg', 'images-1.jpg', 'images-2.jpg', 'images-3.jpg', 'download-3.jpg', 'download-2.jpg', 'download-1.jpg']\n",
      "test: zhong-shui-jiao\n",
      "['download-5.jpg', 'download-4.jpg', 'images.jpg']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xv/z6l8t5rs37s953s_vw3qbgqr0000gn/T/ipykernel_74377/2837067607.py:27: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning dissapear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  train_images = [imageio.imread(os.path.join(img_path,os.path.join(class_id,f))) for f in train_files]\n",
      "/var/folders/xv/z6l8t5rs37s953s_vw3qbgqr0000gn/T/ipykernel_74377/2837067607.py:28: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning dissapear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  validation_images = [imageio.imread(os.path.join(img_path, os.path.join(class_id,f))) for f in validation_files]\n"
     ]
    }
   ],
   "source": [
    "# Load Images using imageio and os package\n",
    "\n",
    "base_dir = '/Users/cap/Dropbox/Cuisines/images'\n",
    "\n",
    "# list all images in each file\n",
    "# in each file split dataset into train and test\n",
    "# add train and test file name to dictionary\n",
    "\n",
    "images_dict = {\n",
    "}\n",
    "\n",
    "for i in range(0, num_foods):\n",
    "    name = food_names[i]\n",
    "    images_dict[name] = []\n",
    "    for img in os.listdir(os.path.join(img_path,name)):\n",
    "        if (img.startswith('.')): continue #ignore hidden files\n",
    "        images_dict[name].append(img)\n",
    "\n",
    "\n",
    "dataset = {}\n",
    "\n",
    "for class_id in images_dict:\n",
    "    images_list = images_dict[class_id]\n",
    "    train_stop = int(len(images_list) * 0.8)\n",
    "    train_files = images_list[:train_stop]\n",
    "    validation_files = images_list[train_stop:]\n",
    "    train_images = [imageio.imread(os.path.join(img_path,os.path.join(class_id,f))) for f in train_files]\n",
    "    validation_images = [imageio.imread(os.path.join(img_path, os.path.join(class_id,f))) for f in validation_files]\n",
    "    dataset[class_id] = {\n",
    "        'train': train_images,\n",
    "        'val': validation_images,\n",
    "        'train_f': train_files,\n",
    "        'val_f': validation_files\n",
    "    }\n",
    "\n",
    "for class_id in dataset:\n",
    "    print('train: {}'.format(class_id), dataset[class_id]['train_f'], sep='\\n')\n",
    "    print('test: {}'.format(class_id), dataset[class_id]['val_f'], sep='\\n')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "856546d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 102/102 [00:02<00:00, 42.87it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import random\n",
    "import skimage.transform as transforms\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print(img_count)\n",
    "\n",
    "class FeatureExtractor:\n",
    "  def __init__(self, in_features=15, out_classes=num_foods):\n",
    "    self.pca = PCA(n_components = in_features)\n",
    "    self.out_classes = out_classes\n",
    "    self.training = True\n",
    "\n",
    "  def extract_features(self, x):\n",
    "    self.pca.fit((x[:, :, 0] + x[:,:,1] + x[:,:,2])/3)\n",
    "    p = self.pca.singular_values_\n",
    "    return p\n",
    "\n",
    "class SimpleDataloader:\n",
    "  def __init__(self, images_dict, shuffle=False, width=224, height=224):\n",
    "    self.feature_extractor = FeatureExtractor()\n",
    "    self.images_dict = images_dict\n",
    "    self.mode = 'train'\n",
    "    self.train_list = []\n",
    "    self.val_list = []\n",
    "    self.shuffle = shuffle\n",
    "    self.width = width\n",
    "    self.height = height\n",
    "    self.train_images = []\n",
    "    self.val_images = []\n",
    "    self.train_features = []\n",
    "    self.val_features = []\n",
    "    pbar = tqdm(total=img_count)\n",
    "    for class_id in self.images_dict:\n",
    "      for i in range(len(self.images_dict[class_id]['train'])):\n",
    "        self.train_list.append((class_id, i))\n",
    "        image = self.transform(self.images_dict[class_id]['train'][i])\n",
    "        features = self.feature_extractor.extract_features(image)\n",
    "        self.train_images.append(image)\n",
    "        self.train_features.append(features)\n",
    "        pbar.update(1)\n",
    "      for i in range(len(self.images_dict[class_id]['val'])):\n",
    "        self.val_list.append((class_id, i))\n",
    "        image = self.transform(self.images_dict[class_id]['val'][i])\n",
    "        features = self.feature_extractor.extract_features(image)\n",
    "        self.val_images.append(image)\n",
    "        self.val_features.append(features)\n",
    "        pbar.update(1)\n",
    "\n",
    "    self.set_mode('train', True)\n",
    "\n",
    "  def set_shuffle(self, shuffle):\n",
    "    self.shuffle = shuffle\n",
    "\n",
    "  def reset_shuffle(self):\n",
    "    self.indexes = list(range(len(self.data_list)))\n",
    "    if self.shuffle:\n",
    "      random.shuffle(self.indexes)\n",
    "      \n",
    "  def set_mode(self, mode, shuffle):\n",
    "    self.set_shuffle(shuffle)\n",
    "    assert mode == 'train' or mode == 'val', 'only supports training and validation'\n",
    "    self.mode = mode\n",
    "    if mode == 'train':\n",
    "      self.data_list = self.train_list\n",
    "      self.data = self.train_images\n",
    "      self.features = self.train_features\n",
    "    else:\n",
    "      self.data_list = self.val_list\n",
    "      self.data = self.val_images\n",
    "      self.features = self.val_features\n",
    "    self.reset_shuffle()\n",
    "\n",
    "  def transform(self, image):\n",
    "    # resize and center crop\n",
    "    # reshape smallest edge to match width and height\n",
    "    height, width, ch = image.shape\n",
    "    if width < height:\n",
    "      new_width = self.width\n",
    "      scale = self.width / width\n",
    "      new_height = int(height * scale)\n",
    "    else:\n",
    "      new_height = self.height\n",
    "      scale = self.height / height\n",
    "      new_width = int(width * scale)\n",
    "    image_tf = transforms.resize(image, (new_height, new_width))\n",
    "\n",
    "    # center crop\n",
    "    w_start = 0\n",
    "    w_stop = self.width\n",
    "    h_start = 0\n",
    "    h_stop = self.height\n",
    "    if new_width > self.width:\n",
    "      start = (new_width - self.width) // 2\n",
    "      w_start = start\n",
    "      w_stop = start + self.width\n",
    "    if new_height > self.height:\n",
    "      start = (new_height - self.height) // 2\n",
    "      h_start = start\n",
    "      h_stop = start + self.height\n",
    "    image_tf = image_tf[h_start:h_stop, w_start:w_stop, :]\n",
    "\n",
    "    return image_tf\n",
    "\n",
    "  def __getitem__(self, data_index):\n",
    "    i = self.indexes[data_index]\n",
    "    class_id, idx = self.data_list[i]\n",
    "    if data_index == len(self.data_list):\n",
    "      self.reset_shuffle\n",
    "    return self.data[i], self.features[i], int(class_id)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data_list)\n",
    "\n",
    "# Create butterfly dataset\n",
    "butterfly_dataloader = SimpleDataloader(dataset, False)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7666ef6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
